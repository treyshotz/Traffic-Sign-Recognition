{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Things to do\n",
    "- Preprocess images\n",
    "- Load images\n",
    "- Set up data for training\n",
    "- Set up feature learning\n",
    "- Add classification\n",
    "- Receive video feed\n",
    "- Process video feed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the path to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['predictionTest', 'Train.csv', 'Test', 'test', 'meta', 'TestWithDirs', 'train', 'Meta', 'Meta.csv', 'Test.csv', 'Train']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(\"../kaggle/\")\n",
    "train_path = f\"{data_dir}/Train/\"\n",
    "test_path = f\"{data_dir}/\"\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset\n",
    "\n",
    "##### About the dataset\n",
    "We chose to split the test folder into 80% for testing and 20% for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: We should consider trying out different batch sizes\n",
    "import tensorflow as tf\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "batch_size = 30\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_size = (img_height, img_width)\n",
    "epochs = 30\n",
    "MIN_IMGS_IN_CLASS = 10\n",
    "\n",
    "class_names = {0: 'Speed limit (20km/h)',\n",
    "               1: 'Speed limit (30km/h)',\n",
    "               2: 'Speed limit (50km/h)',\n",
    "               3: 'Speed limit (60km/h)',\n",
    "               4: 'Speed limit (70km/h)',\n",
    "               5: 'Speed limit (80km/h)',\n",
    "               6: 'End of speed limit (80km/h)',\n",
    "               7: 'Speed limit (100km/h)',\n",
    "               8: 'Speed limit (120km/h)',\n",
    "               9: 'No passing',\n",
    "               10: 'No passing veh over 3.5 tons',\n",
    "               11: 'Right-of-way at intersection',\n",
    "               12: 'Priority road',\n",
    "               13: 'Yield',\n",
    "               14: 'Stop',\n",
    "               15: 'No vehicles',\n",
    "               16: 'Veh > 3.5 tons prohibited',\n",
    "               17: 'No entry',\n",
    "               18: 'General caution',\n",
    "               19: 'Dangerous curve left',\n",
    "               20: 'Dangerous curve right',\n",
    "               21: 'Double curve',\n",
    "               22: 'Bumpy road',\n",
    "               23: 'Slippery road',\n",
    "               24: 'Road narrows on the right',\n",
    "               25: 'Road work',\n",
    "               26: 'Traffic signals',\n",
    "               27: 'Pedestrians',\n",
    "               28: 'Children crossing',\n",
    "               29: 'Bicycles crossing',\n",
    "               30: 'Beware of ice/snow',\n",
    "               31: 'Wild animals crossing',\n",
    "               32: 'End speed + passing limits',\n",
    "               33: 'Turn right ahead',\n",
    "               34: 'Turn left ahead',\n",
    "               35: 'Ahead only',\n",
    "               36: 'Go straight or right',\n",
    "               37: 'Go straight or left',\n",
    "               38: 'Keep right',\n",
    "               39: 'Keep left',\n",
    "               40: 'Roundabout mandatory',\n",
    "               41: 'End of no passing',\n",
    "               42: 'End no passing veh > 3.5 tons'}\n",
    "\n",
    "# train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     \"./../kaggle/Train/\",\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"training\",\n",
    "#     seed=505,\n",
    "#     image_size=img_size,\n",
    "#     shuffle=True,\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "\n",
    "# validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     \"./../kaggle/Train/\",\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"validation\",\n",
    "#     seed=505,\n",
    "#     shuffle=True,\n",
    "#     image_size=img_size,\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "\n",
    "# print(validation_ds)\n",
    "#\n",
    "# num_classes = len(train_ds.class_names)\n",
    "# class_names = train_ds.class_names\n",
    "\n",
    "num_categories = len(os.listdir(train_path))\n",
    "trimmed_dataset = []\n",
    "\n",
    "def load_data(data_dir):\n",
    "    images = list()\n",
    "    labels = list()\n",
    "    for category in range(num_categories):\n",
    "        categories = os.path.join(data_dir, str(category))\n",
    "        size = 0\n",
    "        pos = 0\n",
    "        sub_imgs = os.listdir(categories)\n",
    "        while size < len(sub_imgs) and size < 500:\n",
    "            size+=1\n",
    "            jmp = np.random.randint(1, 3)\n",
    "            pos = (jmp * pos) % len(sub_imgs)\n",
    "            rand_img = sub_imgs[pos]\n",
    "            img = load_img(os.path.join(categories, rand_img), target_size=img_size)\n",
    "            image_arr = img_to_array(img)\n",
    "            images.append(image_arr)\n",
    "            labels.append(category)\n",
    "        trimmed_dataset.append(size)\n",
    "        #\n",
    "        # for img in os.listdir(categories):\n",
    "        #     size+=1\n",
    "        #     if size > 500:\n",
    "        #         break\n",
    "        #     img = load_img(os.path.join(categories, img), target_size=img_size)\n",
    "        #     image = img_to_array(img)\n",
    "        #     images.append(image)\n",
    "        #     labels.append(category)\n",
    "    return images, labels\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# For visualizing images in one batch\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#     for i in range(32):\n",
    "#         ax = plt.subplot(15, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(train_ds.class_names[labels[i]])\n",
    "#         plt.axis(\"off\")\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting the amount of different data from the original dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 37 32 27 41 19 40 39 29 24 20 21 42 36 34 22 30 28 23  6 16 26 15 33\n",
      " 31]\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "for i in range(0, 43):\n",
    "    _, _, files = next(os.walk(f\"../kaggle/TestWithDirs/{i}/\"))\n",
    "    arr.append(len(files))\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "x_pos = [i for i, _ in enumerate(class_names)]\n",
    "plt.bar(x_pos, arr, color=\"blue\")\n",
    "plt.xlabel(\"Class name\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "twentyfive_lowest = np.argsort(arr)[:25]\n",
    "print(twentyfive_lowest)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting the amount of data after trimming the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_9893/1152658521.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstyle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'ggplot'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mx_pos\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclass_names\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_pos\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrimmed_dataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"green\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mxlabel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Class name\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mylabel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Score\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py\u001B[0m in \u001B[0;36mbar\u001B[0;34m(x, height, width, bottom, align, data, **kwargs)\u001B[0m\n\u001B[1;32m   2649\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwidth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.8\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbottom\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malign\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'center'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2650\u001B[0m         data=None, **kwargs):\n\u001B[0;32m-> 2651\u001B[0;31m     return gca().bar(\n\u001B[0m\u001B[1;32m   2652\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwidth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mwidth\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbottom\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbottom\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malign\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0malign\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2653\u001B[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/matplotlib/__init__.py\u001B[0m in \u001B[0;36minner\u001B[0;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1359\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minner\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0max\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1360\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1361\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0max\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msanitize_sequence\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1362\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1363\u001B[0m         \u001B[0mbound\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnew_sig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0max\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001B[0m in \u001B[0;36mbar\u001B[0;34m(self, x, height, width, bottom, align, **kwargs)\u001B[0m\n\u001B[1;32m   2302\u001B[0m                 \u001B[0myerr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_convert_dx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0myerr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_yunits\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2303\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2304\u001B[0;31m         x, height, width, y, linewidth, hatch = np.broadcast_arrays(\n\u001B[0m\u001B[1;32m   2305\u001B[0m             \u001B[0;31m# Make args iterable too.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2306\u001B[0m             np.atleast_1d(x), height, width, y, linewidth, hatch)\n",
      "\u001B[0;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mbroadcast_arrays\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/stride_tricks.py\u001B[0m in \u001B[0;36mbroadcast_arrays\u001B[0;34m(subok, *args)\u001B[0m\n\u001B[1;32m    256\u001B[0m     \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_m\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubok\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msubok\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0m_m\u001B[0m \u001B[0;32min\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 258\u001B[0;31m     \u001B[0mshape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_broadcast_shape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    259\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    260\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mshape\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0marray\u001B[0m \u001B[0;32min\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/stride_tricks.py\u001B[0m in \u001B[0;36m_broadcast_shape\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    187\u001B[0m     \u001B[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    188\u001B[0m     \u001B[0;31m# consistently\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 189\u001B[0;31m     \u001B[0mb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbroadcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    190\u001B[0m     \u001B[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    191\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mpos\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m31\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "x_pos = [i for i, _ in enumerate(class_names)]\n",
    "plt.bar(x_pos, trimmed_dataset, color=\"green\")\n",
    "plt.xlabel(\"Class name\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "twentyfive_lowest = np.argsort(arr)[:25]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images, labels = load_data(train_path)\n",
    "print(len(images))\n",
    "print(trimmed_dataset)\n",
    "# One hot encoding the labels\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# Splitting the dataset into training and test set\n",
    "x_train, x_val, y_train, y_val = train_test_split(np.array(images), labels, test_size=0.2)\n",
    "print(len(x_train))\n",
    "print(len(x_val))\n",
    "print(np.array(images).shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preprocessing images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from cv2 import cv2\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "\n",
    "def augment_imgs(imgs, p):\n",
    "    \"\"\"\n",
    "    Performs a set of augmentations with with a probability p\n",
    "    \"\"\"\n",
    "    from imgaug import augmenters as iaa\n",
    "    augs =  iaa.SomeOf((2, 4),\n",
    "          [\n",
    "              iaa.Crop(px=(0, 4)), # crop images from each side by 0 to 4px (randomly chosen)\n",
    "              iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}),\n",
    "              iaa.Affine(translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}),\n",
    "              iaa.Affine(rotate=(-45, 45)), # rotate by -45 to +45 degrees)\n",
    "              iaa.Affine(shear=(-10, 10)) # shear by -10 to +10 degrees\n",
    "          ])\n",
    "\n",
    "    seq = iaa.Sequential([iaa.Sometimes(p, augs)])\n",
    "    res = seq.augment_images(imgs)\n",
    "    return res\n",
    "\n",
    "x_train = augment_imgs(x_train, 1)\n",
    "x_val = augment_imgs(x_val, 1)\n",
    "\n",
    "plt.imshow(x_train[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "#validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\",\n",
    "                                   input_shape=(img_height,\n",
    "                                                img_width,\n",
    "                                                3)),\n",
    "        tf.keras.layers.RandomRotation(0.1),\n",
    "        tf.keras.layers.RandomZoom(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Activation, MaxPooling2D\n",
    "\n",
    "validation_ds = (x_val, y_val)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# model.add(data_augmentation)\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     data_augmentation,\n",
    "#     tf.keras.layers.Rescaling(1.0 / 255),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(rate=.3),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(720, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(rate=.5),\n",
    "#     tf.keras.layers.Dense(num_categories, activation='softmax')\n",
    "# ])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    #loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    # metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=True,\n",
    "    workers=4\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing/Evaluating the model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Predicting the trained model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from keras_preprocessing.image import load_img\n",
    "\n",
    "wrong_guesses_names = []\n",
    "wrong_guesses_index = []\n",
    "\n",
    "for i in range(0, 43):\n",
    "    img = tf.keras.preprocessing.image.load_img(f\"../kaggle/meta/{i}.png\", target_size=img_size)\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    #input_arr = np.expand_dims(input_arr, axis=0)\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "\n",
    "    predict = model.predict(input_arr)\n",
    "    score = tf.nn.softmax(predict[0])\n",
    "\n",
    "    # plt.style.use('ggplot')\n",
    "    # x_pos = [i for i, _ in enumerate(class_names)]\n",
    "    # plt.bar(class_names.values(), score, color=\"green\")\n",
    "    # plt.xlabel(\"Class name\")\n",
    "    # plt.xticks(rotation='vertical')\n",
    "    # plt.ylabel(\"Score\")\n",
    "    # plt.title(f\"Test on: {class_names[i]}, guess: {class_names[np.argmax(score)]}\")\n",
    "    # plt.figtext(0, 0, f\"Probability:{100 * np.max(score)}\")\n",
    "    # plt.show()\n",
    "\n",
    "    if (i != np.argmax(score)):\n",
    "        wrong_guesses_names.append(class_names[i])\n",
    "        wrong_guesses_index.append(i)\n",
    "\n",
    "    # print(\n",
    "    #      \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    #         .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    # )\n",
    "    # print(sum(score))\n",
    "\n",
    "print(wrong_guesses_names)\n",
    "print(wrong_guesses_index)\n",
    "print(len(wrong_guesses_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding correlation between wrong guesses\n",
    "\n",
    "We have noticed that even though we are getting pretty good accuracy during training, we are still stuggeling to predict images from meta.\n",
    "We therefore take a look at the images with the lowest amount of training data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s1 = set(wrong_guesses_index)\n",
    "intersection = s1.intersection(twentyfive_lowest)\n",
    "print(len(intersection))\n",
    "print(intersection)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "y_test = pd.read_csv(\"../kaggle/\" + 'Test.csv')\n",
    "test_labels = y_test[\"ClassId\"].values\n",
    "test_images = y_test[\"Path\"].values\n",
    "\n",
    "test_labels = np.array(test_labels).astype(np.float)\n",
    "\n",
    "output = list()\n",
    "for img in test_images:\n",
    "    image = load_img(os.path.join(\"../kaggle/\", img), target_size=img_size)\n",
    "    output.append(np.array(image))\n",
    "\n",
    "x_test = np.array(output)\n",
    "prediction = model.predict(x_test, verbose=1)\n",
    "\n",
    "# Convert tests labels in single-digits instead of one-hot encoding\n",
    "Y_pred = np.argmax(prediction, axis=1)\n",
    "\n",
    "#Accuracy with the test data\n",
    "print('Test data accuracy: ', accuracy_score(test_labels, Y_pred) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"../model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}