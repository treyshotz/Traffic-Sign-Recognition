{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Things to do\n",
    "- Preprocess images\n",
    "- Load images\n",
    "- Set up data for training\n",
    "- Set up feature learning\n",
    "- Add classification\n",
    "- Receive video feed\n",
    "- Process video feed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the path to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['predictionTest', 'Train.csv', 'Test', 'test', 'meta', 'TestWithDirs', 'train', 'Meta', 'Meta.csv', 'Test.csv', 'Train']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(\"../kaggle/\")\n",
    "train_path = f\"{data_dir}/Train/\"\n",
    "test_path = f\"{data_dir}/\"\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset\n",
    "\n",
    "##### About the dataset\n",
    "We chose to split the test folder into 80% for testing and 20% for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: We should consider trying out different batch sizes\n",
    "import tensorflow as tf\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "batch_size = 30\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_size = (img_height, img_width)\n",
    "epochs = 15\n",
    "\n",
    "class_names = {0: 'Speed limit (20km/h)',\n",
    "               1: 'Speed limit (30km/h)',\n",
    "               2: 'Speed limit (50km/h)',\n",
    "               3: 'Speed limit (60km/h)',\n",
    "               4: 'Speed limit (70km/h)',\n",
    "               5: 'Speed limit (80km/h)',\n",
    "               6: 'End of speed limit (80km/h)',\n",
    "               7: 'Speed limit (100km/h)',\n",
    "               8: 'Speed limit (120km/h)',\n",
    "               9: 'No passing',\n",
    "               10: 'No passing veh over 3.5 tons',\n",
    "               11: 'Right-of-way at intersection',\n",
    "               12: 'Priority road',\n",
    "               13: 'Yield',\n",
    "               14: 'Stop',\n",
    "               15: 'No vehicles',\n",
    "               16: 'Veh > 3.5 tons prohibited',\n",
    "               17: 'No entry',\n",
    "               18: 'General caution',\n",
    "               19: 'Dangerous curve left',\n",
    "               20: 'Dangerous curve right',\n",
    "               21: 'Double curve',\n",
    "               22: 'Bumpy road',\n",
    "               23: 'Slippery road',\n",
    "               24: 'Road narrows on the right',\n",
    "               25: 'Road work',\n",
    "               26: 'Traffic signals',\n",
    "               27: 'Pedestrians',\n",
    "               28: 'Children crossing',\n",
    "               29: 'Bicycles crossing',\n",
    "               30: 'Beware of ice/snow',\n",
    "               31: 'Wild animals crossing',\n",
    "               32: 'End speed + passing limits',\n",
    "               33: 'Turn right ahead',\n",
    "               34: 'Turn left ahead',\n",
    "               35: 'Ahead only',\n",
    "               36: 'Go straight or right',\n",
    "               37: 'Go straight or left',\n",
    "               38: 'Keep right',\n",
    "               39: 'Keep left',\n",
    "               40: 'Roundabout mandatory',\n",
    "               41: 'End of no passing',\n",
    "               42: 'End no passing veh > 3.5 tons'}\n",
    "\n",
    "# train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     \"./../kaggle/Train/\",\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"training\",\n",
    "#     seed=505,\n",
    "#     image_size=img_size,\n",
    "#     shuffle=True,\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "\n",
    "# validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     \"./../kaggle/Train/\",\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"validation\",\n",
    "#     seed=505,\n",
    "#     shuffle=True,\n",
    "#     image_size=img_size,\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "\n",
    "# print(validation_ds)\n",
    "#\n",
    "# num_classes = len(train_ds.class_names)\n",
    "# class_names = train_ds.class_names\n",
    "\n",
    "num_categories = len(os.listdir(train_path))\n",
    "trimmed_dataset = []\n",
    "\n",
    "def load_data(data_dir):\n",
    "    images = list()\n",
    "    labels = list()\n",
    "    for category in range(num_categories):\n",
    "        categories = os.path.join(data_dir, str(category))\n",
    "        size = 0\n",
    "        # pos = 0\n",
    "        # sub_imgs = os.listdir(categories)\n",
    "        # while size < len(sub_imgs) and size < 500:\n",
    "        #     size+=1\n",
    "        #     jmp = np.random.randint(1, 3)\n",
    "        #     pos = (jmp * pos) % len(sub_imgs)\n",
    "        #     rand_img = sub_imgs[pos]\n",
    "        #     img = load_img(os.path.join(categories, rand_img), target_size=img_size)\n",
    "        #     image_arr = img_to_array(img)\n",
    "        #     images.append(image_arr)\n",
    "        #     labels.append(category)\n",
    "        # trimmed_dataset.append(size)\n",
    "\n",
    "        for img in os.listdir(categories):\n",
    "            size+=1\n",
    "            if size > 500:\n",
    "                break\n",
    "            img = load_img(os.path.join(categories, img), target_size=img_size)\n",
    "            image = img_to_array(img)\n",
    "            images.append(image)\n",
    "            labels.append(category)\n",
    "    return images, labels\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# For visualizing images in one batch\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#     for i in range(32):\n",
    "#         ax = plt.subplot(15, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(train_ds.class_names[labels[i]])\n",
    "#         plt.axis(\"off\")\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting the amount of different data from the original dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 37 32 27 41 19 40 39 29 24 20 21 42 36 34 22 30 28 23  6 16 26 15 33\n",
      " 31]\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "for i in range(0, 43):\n",
    "    _, _, files = next(os.walk(f\"../kaggle/TestWithDirs/{i}/\"))\n",
    "    arr.append(len(files))\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "x_pos = [i for i, _ in enumerate(class_names)]\n",
    "plt.bar(x_pos, arr, color=\"blue\")\n",
    "plt.xlabel(\"Class name\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "twentyfive_lowest = np.argsort(arr)[:25]\n",
    "print(twentyfive_lowest)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "images, labels = load_data(train_path)\n",
    "print(len(images))\n",
    "print(trimmed_dataset)\n",
    "# One hot encoding the labels\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# Splitting the dataset into training and test set\n",
    "x_train, x_val, y_train, y_val = train_test_split(np.array(images), labels, test_size=0.2)\n",
    "print(len(x_train))\n",
    "print(len(x_val))\n",
    "print(np.array(images).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting the amount of data after trimming the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "x_pos = [i for i, _ in enumerate(class_names)]\n",
    "plt.bar(x_pos, trimmed_dataset, color=\"green\")\n",
    "plt.xlabel(\"Class name\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "twentyfive_lowest = np.argsort(arr)[:25]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preprocessing images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from skimage.color import rgb2gray\n",
    "from cv2 import cv2\n",
    "\n",
    "\n",
    "def augment_imgs(imgs, p):\n",
    "    \"\"\"\n",
    "    Performs a set of augmentations with with a probability p\n",
    "    \"\"\"\n",
    "    from imgaug import augmenters as iaa\n",
    "    augs =  iaa.SomeOf((2, 4),\n",
    "          [\n",
    "              iaa.Crop(px=(0, 4)), # crop images from each side by 0 to 4px (randomly chosen)\n",
    "              iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}),\n",
    "              iaa.Affine(translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}),\n",
    "              iaa.Affine(rotate=(-45, 45)), # rotate by -45 to +45 degrees)\n",
    "              iaa.Affine(shear=(-10, 10)) # shear by -10 to +10 degrees\n",
    "          ])\n",
    "\n",
    "    seq = iaa.Sequential([iaa.Sometimes(p, augs)])\n",
    "    res = seq.augment_images(imgs)\n",
    "    return res\n",
    "\n",
    "#plt.imshow(images[0])\n",
    "#x_train = augment_imgs(x_train, 1)\n",
    "# x_val = augment_imgs(x_val, 1)\n",
    "\n",
    "#x_train = rgb2gray(x_train)\n",
    "\n",
    "plt.imshow(x_train[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "#validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\",\n",
    "                                   input_shape=(img_height,\n",
    "                                                img_width,\n",
    "                                                3)),\n",
    "        tf.keras.layers.RandomRotation(0.1),\n",
    "        tf.keras.layers.RandomZoom(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Activation, MaxPooling2D\n",
    "\n",
    "validation_ds = (x_val, y_val)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(data_augmentation)\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     data_augmentation,\n",
    "#     tf.keras.layers.Rescaling(1.0 / 255),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(rate=.3),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(720, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(rate=.5),\n",
    "#     tf.keras.layers.Dense(num_categories, activation='softmax')\n",
    "# ])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    #loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    # metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=True,\n",
    "    workers=4\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing/Evaluating the model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Predicting the trained model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from keras_preprocessing.image import load_img\n",
    "\n",
    "wrong_guesses_names = []\n",
    "wrong_guesses_index = []\n",
    "\n",
    "for i in range(0, 43):\n",
    "    img = tf.keras.preprocessing.image.load_img(f\"../kaggle/meta/{i}.png\", target_size=img_size)\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    #input_arr = np.expand_dims(input_arr, axis=0)\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "\n",
    "    predict = model.predict(input_arr)\n",
    "    score = tf.nn.softmax(predict[0])\n",
    "\n",
    "    # plt.style.use('ggplot')\n",
    "    # x_pos = [i for i, _ in enumerate(class_names)]\n",
    "    # plt.bar(class_names.values(), score, color=\"green\")\n",
    "    # plt.xlabel(\"Class name\")\n",
    "    # plt.xticks(rotation='vertical')\n",
    "    # plt.ylabel(\"Score\")\n",
    "    # plt.title(f\"Test on: {class_names[i]}, guess: {class_names[np.argmax(score)]}\")\n",
    "    # plt.figtext(0, 0, f\"Probability:{100 * np.max(score)}\")\n",
    "    # plt.show()\n",
    "\n",
    "    if (i != np.argmax(score)):\n",
    "        wrong_guesses_names.append(class_names[i])\n",
    "        wrong_guesses_index.append(i)\n",
    "\n",
    "    # print(\n",
    "    #      \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    #         .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    # )\n",
    "    # print(sum(score))\n",
    "\n",
    "print(wrong_guesses_names)\n",
    "print(wrong_guesses_index)\n",
    "print(len(wrong_guesses_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding correlation between wrong guesses\n",
    "\n",
    "We have noticed that even though we are getting pretty good accuracy during training, we are still stuggeling to predict images from meta.\n",
    "We therefore take a look at the images with the lowest amount of training data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s1 = set(wrong_guesses_index)\n",
    "intersection = s1.intersection(twentyfive_lowest)\n",
    "print(len(intersection))\n",
    "print(intersection)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "y_test = pd.read_csv(\"../kaggle/\" + 'Test.csv')\n",
    "test_labels = y_test[\"ClassId\"].values\n",
    "test_images = y_test[\"Path\"].values\n",
    "\n",
    "test_labels = np.array(test_labels).astype(np.float)\n",
    "\n",
    "output = list()\n",
    "for img in test_images:\n",
    "    image = load_img(os.path.join(\"../kaggle/\", img), target_size=img_size)\n",
    "    output.append(np.array(image))\n",
    "\n",
    "x_test = np.array(output)\n",
    "prediction = model.predict(x_test, verbose=1)\n",
    "\n",
    "# Convert tests labels in single-digits instead of one-hot encoding\n",
    "Y_pred = np.argmax(prediction, axis=1)\n",
    "\n",
    "#Accuracy with the test data\n",
    "print('Test data accuracy: ', accuracy_score(test_labels, Y_pred) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"../model.h5\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}